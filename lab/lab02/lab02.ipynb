{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2:  Loss and risk\n",
    "Welcome to the second Data 102 lab! \n",
    "\n",
    "The goal of this lab is to introduce loss functions in hypothesis testing problems.\n",
    "\n",
    "The code and responses you need to write are commented out with a message **\"TODO: fill ...\"**. There is additional documentation for each part as you go along.\n",
    "\n",
    "\n",
    "## Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "## Submission\n",
    "To submit this assignment, rerun the notebook from scratch (by selecting Kernel > Restart & Run all), and then print as a pdf (File > download as > pdf) and submit it to Gradescope.\n",
    "\n",
    "**For full credit, this assignment should be completed and submitted before Wednesday, Sep 15, 2021 at 11:59 PM. PST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborators\n",
    "Write the names of your collaborators in this cell.\n",
    "\n",
    "`<Collaborator Name> <Collaborator e-mail>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import itertools\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "import hashlib\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"dark\")\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "def get_hash(num):\n",
    "    \"\"\"Helper function for assessing correctness\"\"\"\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Custom Loss Functions for Hypothesis Testing\n",
    "\n",
    "The first question looks at a medical diagnostic decisions. For each person that undergoes testing, the null hypothesis is that they don't have the virus, and the alternative is that they do.\n",
    "\n",
    "_The null hypothesis_ $H_0$: Person $X$ does not have the virus.\n",
    "\n",
    "_The alternative hypothesis_ $H_1$: Person $X$ has the virus.\n",
    "\n",
    "Suppose that you devise a test which takes some measurements from each test subject and then computes a corresponding p-value.\n",
    "\n",
    "Last week we looked at several approaches for controllling False Positive Rate (FPR), Family Wise Error Rate (FWER) and False Discovery Rate (FDR). However, they all have some drawbacks for medical decision making: FPR and FWER do not depend on the prevalence of the disease and neither of them allows a decision maker to consider different misclassification costs arising from false-negative and false-positive diagnoses.\n",
    "\n",
    "When making medical decisions, wrong diagnoses carry different costs. Deciding that a patient does not have the virus when in reality they do is a **False Negative**. The potential consequences of such decision are severe: lack of treatment, risk of infecting others, and even premature death.\n",
    "\n",
    "On the other hand, deciding that a patient has the virus when in reality they don't is a **False Positive**. The potential consequences of that include distress, unnecesary treatment and costs of subsequent testing. This is certainly not ideal, but less severe than the consequences of a false negative.\n",
    "\n",
    "We've previously evaluated decisions in terms of their TPR and FPR, and showed how ROC curves demonstrate the trade-off curve between the two quantities. We saw that it is not always clear how to choose the best trade-off.\n",
    "\n",
    "A very popular way of choosing the trade-off, and simultaneously comparing different procedures, is the idea of **risk** that we learnt in Lecture 5. Here, the analyst constructs a loss function by specifying the **cost** of making each type of mistake.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we estimate the cost of making a false negative mistake to be $k$-times larger than the cost of a false positive. We can express that via a **loss function**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Checkpoint: fill in the missing value here\n",
    "\n",
    "$$\\begin{cases} \\mathcal{l}(D=1|R=0) = 1\\\\\n",
    "\\mathcal{l}(D=0|R=1) = ~?\\\\\n",
    "\\mathcal{l}(D=0|R=0)=\\mathcal{l}(D=1|R=1) = 0\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint: Does FPR and FWER depend on the prevalence of the disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "`TODO: fill in with your answer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint: Above, you were given one example of when the consequences of a False Negative is more sever than the consequences of a False Positive. Come up with one example of the opposite: when the consequences of a False Positive is more severe than the consequences of a False Negative. \n",
    "\n",
    "Please include the null and alternate hypothesis as well as what FP and FN would correspond to & what are the consequences of FP and FN with respect to your null and alternate hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "`TODO: fill in with your answer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.a: Compute average empirical loss\n",
    "\n",
    "Assume we have a sample of $N$ patients for which a test outputs the following confusion matrix: \n",
    "\n",
    "|             | Decision = 0 | Decision = 1 |\n",
    "|-------------|--------------|--------------|\n",
    "| Reality = 0 | TN           | FP           |\n",
    "| Reality = 1 | FN           | TP           |\n",
    "\n",
    "### Compute the average loss this procedure incurs by summing up the losses for every mis-diagnosis and then dividing by the total number of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in\n",
    "def compute_average_loss(results_dictionary, factor_k):\n",
    "    \"\"\" Function that computes average loss for a given confusion matrix and a multiplicaltive\n",
    "        k_factor that compares the consequences of false nagatives and false positives.\n",
    "        \n",
    "        Inputs:\n",
    "            results_dictionary : a dictionary with the counts of TP, FP, TN and FN\n",
    "            k_factor : float, quantifies the ratio of the negative consequences of\n",
    "                       false negatives compared to false positives\n",
    "                       \n",
    "        Outputs:\n",
    "            average_loss : float\n",
    "    \"\"\"\n",
    "    \n",
    "    TP_count = results_dictionary['TP_count']\n",
    "    FP_count = results_dictionary['FP_count']\n",
    "    TN_count = results_dictionary['TN_count']\n",
    "    FN_count = results_dictionary['FN_count']\n",
    "    \n",
    "    average_loss = # TODO: fill in\n",
    "    return(average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running validation tests: Do not modify\n",
    "res_dict = {'TP_count': 100, 'FP_count': 20, 'TN_count':450, 'FN_count':30}\n",
    "k_factors = [0, 10, 100]\n",
    "hash_list = ['ab51c1986c756154d0e3feb4f5a5e829','91f25a837f3db78306b0ad2ef0437ff9','3fc1803a77013426e6707b041de152db']\n",
    "for i, k in enumerate(k_factors):\n",
    "    average_loss = compute_average_loss(res_dict, k)\n",
    "    print(\"For k = {}, the average loss is {:.3f}\".format(k, average_loss))\n",
    "    assert hash_list[i] == get_hash(average_loss)\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b: Compute the average loss (empirical risk) with respect to various levels $\\alpha$\n",
    "\n",
    "In this part we will use a simple test that rejects the null hypothesis whenever the p-value of a patient is smaller than some level $\\alpha$. \n",
    "\n",
    "Our goal is to investigate the performance of the test at different levels with respect to the custom loss defined in **1.a**. \n",
    "\n",
    "Hint: Recall the naive test from Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: don't make any changes to this function, this is exatly the naive thresholding you completed in Lab 1\n",
    "def alpha_threshold_decisions(p_values, alpha):\n",
    "    \"\"\"\n",
    "    Returns decisions on p-values using naive thresholding.\n",
    "    \n",
    "    Inputs:\n",
    "        p_values: array of p-values\n",
    "        alpha: threshold (significance level)\n",
    "    \n",
    "    Returns:\n",
    "        decisions: binary array of same length as p-values, where `decisions[i]` is 1\n",
    "        if `p_values[i]` is deemed significant at level `alpha`, and 0 otherwize\n",
    "    \"\"\"\n",
    "    decisions = p_values <= alpha\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also bring in from Lab 01 the function that computes the counts of TP, TN, FP, FN by comparing the decision to the reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: don't make any changes to this function, this is the report_results function you completed in Lab 1\n",
    "def report_results(decisions, reality):\n",
    "    \"\"\"\n",
    "    Produces a dictionary with counts for the true positives, true negatives,\n",
    "    false negatives, and false positives from the input `decisions`\n",
    "    and `reality` arrays.\n",
    "    \n",
    "    Inputs:\n",
    "      decision: array of 0/1 values where 1 indicates that patient has the virus.\n",
    "      reality: array of 0/1 values where 1 indicates a draw from the alternative.\n",
    "    \n",
    "    Outputs: a dictionary of TN, TP, FN, and FP counts.\n",
    "    \"\"\"   \n",
    "    \n",
    "    TP_count = np.sum(decisions*reality)\n",
    "    TN_count = np.sum((1-decisions)*(1-reality))\n",
    "    FP_count = np.sum((decisions)*(1-reality))\n",
    "    FN_count = np.sum((1-decisions)*(reality))\n",
    "    \n",
    "    results_dictionary = {\"TN_count\": TN_count,\n",
    "                          \"TP_count\": TP_count,\n",
    "                          \"FN_count\": FN_count,\n",
    "                          \"FP_count\": FP_count,\n",
    "                         }\n",
    "    return results_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will generate ground truth data. \n",
    "\n",
    "Assume there are $N$ subjects, out of which a fraction trully have the virus. This fraction is known as **prevalence**: $\\mathbb{P}\\{R=1\\}$.\n",
    "\n",
    "The function below generates p-values associated with each test subject. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: don't make any changes to this function\n",
    "def generate_ground_truth(N, prevalence):\n",
    "    \"\"\" Creates simulated p-values corresponding to N subjects at a \n",
    "    specified disease prevalence level\"\"\"\n",
    "    rs = np.random.RandomState(1)\n",
    "    reality = rs.binomial(1, prevalence, N)\n",
    "    p_values = 1 - norm.cdf(rs.randn(N) + reality)\n",
    "    return(p_values, reality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate p-values: Do not modify\n",
    "N = 10000\n",
    "prevalence = 0.1\n",
    "p_values, reality = generate_ground_truth(N, prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the cell below complete the function that computes the average loss (empirical risk) for an $\\alpha$ level test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def compute_alpha_average_loss(p_values, reality, alpha, factor_k):\n",
    "    \"\"\" \n",
    "    Computes the observed average loss for an alpha level test.\n",
    "    \n",
    "    Inputs:\n",
    "        p_values: array of floats, p-value[i] is the p-values associated with test subject i.\n",
    "        reality: array of 0/1s\n",
    "        alpha: float, threshold for rejecting the null hypothesis\n",
    "        factor_k: float, quantifies the ratio of the negative consequences of\n",
    "                  false negatives compared to false positives\n",
    "                  \n",
    "    Outputs:\n",
    "        average_loss: float, average observed loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # HINT: Your code should take advantage of functions already defined in this notebook.\n",
    "    average_loss = # TODO: fill in\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests do not modify\n",
    "alpha_values = [0.05, 0.1, 0.2, 0.4]\n",
    "k_factors = [0, 10, 100]\n",
    "inputs = list(itertools.product(alpha_values, k_factors))\n",
    "outputs = [compute_alpha_average_loss(p_values, reality, *inp) for inp in inputs]\n",
    "\n",
    "hash_list = ['8d0a5f87d0563079e70969b527b22b2c', '1370c7dde8b12484e1f9f3376ec72693', \n",
    "             'f106401a6d5ceaa1a89d99bcc773f8db', 'd92f2ab695c640d68b7b0f055704d892', \n",
    "             '066517035812371facdef5f27ff5c7c9', '91709ca4894f058b311f697527479564', \n",
    "             '49f12f9c625759e7bb9e3f2fe5cee530', '38888496421ef7c75527678f1e718c19', \n",
    "             '701a4e33513e8e55f91eac027a42b6fe', 'a6107b1736a62ac0c1c79546cc4ec85f', \n",
    "             'd1d940b705c4e66fc40cd8ea1c2f7c57', 'a57b99387860e7d6b6de25ea47201a0b']\n",
    "\n",
    "for i, inp in enumerate(inputs):\n",
    "    print('At level alpha={} and k={} the average loss is {:.3f}'.format(*inp, outputs[i]))\n",
    "    assert(get_hash(outputs[i])==hash_list[i])\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c Investigate the average loss plot for different levels of disease prevalence \n",
    "The function below generates ground truth for a sample of 10000 subjects for a given disease prevalence. It then computes the average loss for diagnostic decisions at level $\\alpha$, where $\\alpha \\in [0, 1]$ . Finally, it plots the resulting average loss (y axis) at a level $\\alpha$ (x axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this as is after completing the `compute_alpha_average_loss` function\n",
    "# Do not modify\n",
    "def plot_average_loss(prevalence, factor_k):\n",
    "    N = 10000\n",
    "    # generate ground truth\n",
    "    p_values, reality = generate_ground_truth(N, prevalence)\n",
    "    # vary alpha from 0 to 1\n",
    "    alpha_array = np.arange(0,1, 0.05)\n",
    "    # compute average loss for each alpha\n",
    "    average_loss_array = [compute_alpha_average_loss(p_values, reality, alpha, factor_k) for alpha in alpha_array]\n",
    "    optimal_alpha = alpha_array[np.argmin(average_loss_array)]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(alpha_array, average_loss_array, label = 'Average Loss')\n",
    "    plt.axvline(x=optimal_alpha, ls='--', label = 'Optimal $\\\\alpha$', c='green')\n",
    "    plt.xlabel('$\\\\alpha$ level')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.legend()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize interactive plot: Do not modify\n",
    "interactive_plot = interactive(plot_average_loss, prevalence=(0.001, 0.11, 0.01), factor_k=(0, 100, 5))\n",
    "interactive_plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c (i) Fix the `prevalence` of the disease at $0.05$ ($5\\%$). Using the slider in the interactive plot above, try out different values for the multiplicative `factor_k`. What do you notice? How would you adjust your diagnosic procedure based on the value of `factor_k`? What combination of `factor_k` and $\\alpha$ gives you the lowest possible loss, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO: fill in your response here`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c (ii) Fix `factor_k` at $50$ (meaning that the negative consequence of a false negative are 50 times larger than the negative consequences of a false positive). Using the slider in the interactive plot above, try out different values for the true prevalence of the disease. What do you notice? How would you adjust your diagnostic procedure based on the prevalence of the disease? What combination of prevalence and $\\alpha$ gives you the lowest possible loss, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO: fill in your response here`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Question 2.\n",
    "In the previous question you played the role of a test designer or device manufacturer that needs to find an appropriate way to calibrate the test such that it minizes some desired loss. In this part put yourself in the shoes of a medical professional who is using this testing device without really knowing all the internals of it. \n",
    "\n",
    "The test kit claims a certain specificity ($1-FPR$) and sensitivity ($1-FNR$). \n",
    "\n",
    "Assume you have a new patient that came in and tested positive (you have only the binary output of the test). Your goal is to determine whether or not to put this patient through treatment.\n",
    "\n",
    "To answer this we weill make the following assumptions:\n",
    "- Assume as in part 1, that getting a false negative is $k$ times worse than getting a false positive.\n",
    "- Assume that you know the `prevalence` of this disease.\n",
    "- Assume that the test has a certain `specificity` and `sensitivity`.\n",
    "\n",
    "## 2.a Compute the posterior\n",
    "Complete function below to compute the posterior probability that the patient truly has the disease conditioned on a positive test result: namely, compute $\\mathbb{P}\\{R=1|D=1\\}$ as a function of `prevalence`, `sensitivity` and `specificity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def compute_posterior_probability(prevalence, sensitivity, specificity):\n",
    "    \"\"\" \n",
    "    Computes the posterior probability that the patient trully has the disease \n",
    "    conditioned on a positive test result.\n",
    "    \n",
    "    Inputs: \n",
    "        prevalence: float, fraction of the population that has the disease\n",
    "        sensitivity: float, 1 - false negative rate\n",
    "        specificity: float, 1 - false positive rate\n",
    "        \n",
    "    Outputs:\n",
    "        posterior probability: probability that the patient has the disease given a positive test result\n",
    "    \"\"\"\n",
    "    posterior_probability = # TODO: fill in\n",
    "    return posterior_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: We've already seen this in HW1 and discussion 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute a few posterior probabilities\n",
    "prevalence = [0.001, 0.1]\n",
    "sensitivity = 0.98\n",
    "specificity = 0.99\n",
    "print('Conditioned on a positive test result, with sensitivity {} and specificity {}:'.format(sensitivity, specificity))\n",
    "print('For a low prevalence disesase ({}), the posterior probability that the test subject is truly positive is {:.3f}'.\n",
    "      format(prevalence[0], compute_posterior_probability(prevalence[0], sensitivity, specificity)))\n",
    "print('For a high prevalence disesase ({}), the posterior probability that the test subject is truly positive is {:.3f}'.\n",
    "      format(prevalence[1], compute_posterior_probability(prevalence[1], sensitivity, specificity)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: Do not modify\n",
    "prevalences = [0.001, 0.01, 0.1]\n",
    "sensitivities = [1, 0.95, 0.9, 0.8]\n",
    "specificities = [1, 0.99, 0.95, 0.9]\n",
    "inputs = list(itertools.product(prevalences, sensitivities, specificities))\n",
    "hash_list = ['e4c2e8edac362acab7123654b9e73432', '821e0d2e8ad5f72b93bd6fb0fc26f535', '236421e867622df2f607cdb5189c70d1', \n",
    "             'a9206adc53f2eb4d2abd080afda200bd', 'e4c2e8edac362acab7123654b9e73432', '9c03d13c0a39b2556ecae42016c9d675', \n",
    "             '0760e852d0b05e2ef5e11d00dd1a2127', '1fa1dfcd0d376e4c9a0032e777a6d067', 'e4c2e8edac362acab7123654b9e73432', \n",
    "             '836670242f6bceeffd0cbfd6bc14df48', '7385c68c0dac26a8ded77665739239b1', '7a8d3f23e6243e59e639d771996113ad', \n",
    "             'e4c2e8edac362acab7123654b9e73432', '21fc088cf551577826cf8c219d9e58ee', 'c437b8af10263021fb63b161acec35da', \n",
    "             '7e43eb2d1790b3035225e2bb9163b8d6', 'e4c2e8edac362acab7123654b9e73432', 'a48200cf8083cdcf827e7130a731347b', \n",
    "             'b6725672c476046f80280ca006050343', '304673fd056ee01f4006f584ea2e967f', 'e4c2e8edac362acab7123654b9e73432', \n",
    "             '9102ddf17e54e6e9e123e4907ae22881', '494fb4c19d69fbb920fe5e5eb537fec2', '4616ccbd5cc0e447cac7bfd2865406fd', \n",
    "             'e4c2e8edac362acab7123654b9e73432', '9710f0de9b0b1df0db92e040b905480a', 'b75111ed7f673be12646128662c28934', \n",
    "             '02ca14438cfad625ce3c29f01987587a', 'e4c2e8edac362acab7123654b9e73432', 'e0aee5a60b2604d54f9579b6fbe9ece6', \n",
    "             'ab5a7f1a2fd4a4fa9c14deb0d1ca74bc', '2f10b50859fa15fdedf273c8e6f445dd', 'e4c2e8edac362acab7123654b9e73432', \n",
    "             '8e34a505d9b9ac3aebe6f7613c2e2112', '56f775f1d0cc4794ef7250830b193672', 'e6b2cd038850001bb598a3212f8a42b9', \n",
    "             'e4c2e8edac362acab7123654b9e73432', '2599547e9eebc634eaf8d15dc58ce1cb', 'd82e3e9cec933da4ec5be4657d4e3d97', \n",
    "             'dff06c0e6c489d05bd83aa8cce6455fb', 'e4c2e8edac362acab7123654b9e73432', '90c55616ca660fd74557bad8cead21c3', \n",
    "             '0ee1068fd889d0595a7675bab243ebb3', 'd75a11292410fe7ee7aa186da66ab3ec', 'e4c2e8edac362acab7123654b9e73432', \n",
    "             'fa7f3c58395ca34434b27928f3277ee2', '4601230ad9e902f6803f2d44c80f5d5d', '433ec118e18fd86015c0173339e1482e']\n",
    "\n",
    " \n",
    "for inp, hash_val in zip(inputs, hash_list):\n",
    "    output = compute_posterior_probability(*inp)\n",
    "    assert (get_hash(output) == hash_val)\n",
    "print('Test passed!')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b Compute expected loss function with respect to posterior distribution\n",
    "\n",
    "Given that the test returned a positive result (that $D=1$), you can make one of two posible decisions:\n",
    " - $T = 1$: start the treatment\n",
    " - $T = 0$: do not start the treatment despite the positive test result\n",
    " \n",
    "Similarly to Question 1, let's assume that we estimate the cost of not treating a truly sick patient to be $k$ times larger than the cost of treating a patient that is not truly sick.\n",
    "\n",
    "Recall from lecture that a loss function takes in a hidden state of the world $\\theta$ (in this case, that's the reality $R$: whether or not the patient is sick), and a decision $\\delta$ (in this case, that's $T$: whether or not to treat). Our loss function has the formula:\n",
    "\n",
    "$$\\begin{cases} \\ell(R=0, T=1) = 1\\\\\n",
    "\\ell(R=1, T=0) = k\\\\\n",
    "\\ell(R=0, T=0)=\\ell(R=1, T=1) = 0\\end{cases}$$\n",
    "\n",
    "### Compute the expected loss for each treatment decision, given that someone tested positive:\n",
    "$$\\mathbb{E}[l(R,T=0)|D=1] = ?$$\n",
    "$$\\mathbb{E}[l(R,T=1)|D=1] = ?$$\n",
    "\n",
    "*Hint: Think carefully about what is random here. What's it's distribution?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def compute_expected_loss(treatment, posterior_probability, factor_k):\n",
    "    \"\"\" \n",
    "    Compute the expected loss for the treatment.\n",
    "    \n",
    "    Inputs:\n",
    "        treatment: int 0/1 (0-no treatment, 1-treatment)\n",
    "        posterior_probability: float, probability that the patient is truly sick given positive test result\n",
    "        k_factor : float, quantifies the ratio of the negative consequences of\n",
    "                   false negatives compared to false positives\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    expected_loss = # TODO: fill in\n",
    "    return(expected_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation tests: Do not modify\n",
    "treatments = [0, 1]\n",
    "k_factors = [0, 10, 100]\n",
    "posterior_probabilities = [0.1, 0.5, 0.9]\n",
    "inputs = list(itertools.product(treatments, posterior_probabilities, k_factors))\n",
    "hash_list = ['30565a8911a6bb487e3745c0ea3c8224', 'e4c2e8edac362acab7123654b9e73432',\n",
    "             '43a1437f7f656cd8be7c996c58719e0a', '30565a8911a6bb487e3745c0ea3c8224',\n",
    "             '336669dbe720233ed5577ddf81b653d3', '88bce6f1bd04b8521f1167b5a6dec118',\n",
    "             '30565a8911a6bb487e3745c0ea3c8224', 'cf5f238fca8b6e155078aa41c175743a',\n",
    "             'a5efe444b4090e202d78340494947f63', 'a894124cc6d5c5c71afe060d5dde0762',\n",
    "             'a894124cc6d5c5c71afe060d5dde0762', 'a894124cc6d5c5c71afe060d5dde0762',\n",
    "             'd310cb367d993fb6fb584b198a2fd72c', 'd310cb367d993fb6fb584b198a2fd72c',\n",
    "             'd310cb367d993fb6fb584b198a2fd72c', 'ec705edd9065ac64dc3985903df2e2e6',\n",
    "             'ec705edd9065ac64dc3985903df2e2e6', 'ec705edd9065ac64dc3985903df2e2e6']\n",
    "for i, inp in enumerate(inputs):\n",
    "    assert (get_hash(compute_expected_loss(*inp)) == hash_list[i])\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c Loss and Risk\n",
    "Is the quantity you computed above a frequentist risk, a Bayesian posterior risk, or neither? Explain why in two sentences or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO: fill in your response here`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.d Decide whether or not to administer the treatment by comparing the expected losses in each case.\n",
    "\n",
    "Compare the cost for `treatment T=1` and `no treatment T=0` and choose the option with lower expected loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def make_decision(posterior_probability, factor_k):\n",
    "    \"\"\"\n",
    "    Make a decisions to adminster or not the treatment: T=1 or T=0 .\n",
    "    \n",
    "    Inputs: \n",
    "        posterior_probability: float, probability that the patient is truly sick given positive test result\n",
    "        k_factor : float, quantifies the ratio of the negative consequences of\n",
    "                   false negatives compared to false positives\n",
    "    Outputs:\n",
    "        treatment: int, 0/1\n",
    "    \"\"\"\n",
    "    \n",
    "    treatment = # TODO: fill in\n",
    "    return treatment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_factors = [0, 10, 100]\n",
    "posterior_probabilities = [0.1, 0.5, 0.9]\n",
    "inputs= list(itertools.product(posterior_probabilities, k_factors))\n",
    "hash_list = ['cfcd208495d565ef66e7dff9f98764da', 'c4ca4238a0b923820dcc509a6f75849b',\n",
    "             'c4ca4238a0b923820dcc509a6f75849b', 'cfcd208495d565ef66e7dff9f98764da',\n",
    "             'c4ca4238a0b923820dcc509a6f75849b', 'c4ca4238a0b923820dcc509a6f75849b',\n",
    "             'cfcd208495d565ef66e7dff9f98764da', 'c4ca4238a0b923820dcc509a6f75849b',\n",
    "             'c4ca4238a0b923820dcc509a6f75849b']\n",
    "for i, inp in enumerate(inputs):\n",
    "    assert (get_hash(make_decision(*inp)) == hash_list[i])\n",
    "print(\"All tests passed! You are awesome!\")\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('baby_otter.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "imgplot.axes.get_xaxis().set_visible(False)\n",
    "imgplot.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
