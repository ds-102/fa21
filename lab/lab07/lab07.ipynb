{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Estimating Causal Effects via Instrumental Variables\n",
    "Welcome to the seventh DS102 lab! \n",
    "\n",
    "The goals of this lab is to implement and get better understanding of Instrumental Variables discussed in Lecture on March 16. Along with Inverse Propensity Scaling which we discussed in Lecture, Instrumental Variables are often used to determine causal effects.\n",
    "\n",
    "The code you need to write is commented out with a message \"TODO: fill in\".\n",
    "\n",
    "## Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "## Gradescope Submission\n",
    "To submit this assignment, rerun the notebook from scratch (by selecting Kernel > Restart & Run all), and then print as a pdf (File > download as > pdf) and submit it to Gradescope.\n",
    "\n",
    "\n",
    "**This assignment should be completed and submitted before Sunday, March 21, 2021 at 11:59 PM. PST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborators\n",
    "Write the names of your collaborators in this cell.\n",
    "\n",
    "`<Collaborator Name> <Collaborator e-mail>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "import hashlib\n",
    "\n",
    "sns.set(style=\"dark\")\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumental Variables Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we measure $X_1$, the number of books a student read in the last year, and we are intrested in determing how $X_1$ affects an observed target outcome $Y$, the student's SAT score. The effect we are interested in is **causal** because we want to know how $Y$ changes if all randomness other than $X_1$ remains fixed, and only $X_1$ changes. We will refer to $X_1$ as the \"treatment\". In general, $X_1$ might be multi-dimensional, however for the purpose of this exercise we take $X_1 \\in\\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose there's also a confounder $X_2$, which is the income of the student's family. We don't observe $X_2$, but it affects both the number of books the student reads (wealthier families may have more access to books) and the student's SAT score (wealthier students may have more access to SAT tutoring).\n",
    "\n",
    "We assume that the outcome is generated as a linear function of the confounder $X_2$ and treatment $X_1$, with additive noise $\\epsilon$:\n",
    "$$$$\n",
    "$$Y = \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon.$$\n",
    "\n",
    "The goal is to estimate $\\beta_1$, the true causal effect of the number of books a student reads on their SAT score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danger of bias\n",
    "As we saw in Discussion 7, if the confounder $X_2$ is highly correlated with $X_1$, performing ordinary least squares (OLS) on the observed data $X_1$, $Y$ can lead to very biased results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrumental variables (IVs) and two-stage least squares (2SLS)\n",
    "\n",
    "One way to get around this issue is by using **instrumental variables (IVs)**. A valid instrument $Z$ is a variable which is independent of the confounder $X_2$, and affects $Y$ only through $X_1$. For example, we can create such an instrument $Z$ by employing *encouragement design*, where we randomly assign students to \"readathons\" of different durations. See the figure below for a causal diagram:\n",
    "\n",
    "![](causal_diagram.png)\n",
    "\n",
    "Using the instrumental variable $Z$, we can estimate $\\beta_1$ by first \"guessing\" $X_1$ from $Z$ using ordinary least squares (OLS) (denoted $\\hat X_1$), and then regressing $Y$ onto $\\hat X_1$ (instead of $X_1$) using OLS as well. This procedure is known as **two-stage least squares (2SLS)**. \n",
    "\n",
    "In this lab, we will observe the bias that can occur when naively performing OLS on the observed data $X_1, Y$, and also how employing 2SLS can achieve a better estimate of $\\beta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup\n",
    "\n",
    "Suppose that we have historical data from $n=10,000$ different students. Suppose we observe the following variables: \n",
    "\n",
    "$X_1^{(i)} =$ number of books the student read in the last year, \n",
    "\n",
    "$Z^{(i)} = $ duration of the \"readathon\" at the student's school. *Note: This is sligtly different from the setup in Discussion 7 where it was a binary variable* \n",
    "\n",
    "$Y^{(i)} = $ the student's SAT score. \n",
    "\n",
    "Suppose that the student's family income $X_2^{(i)}$ affects both $X_1^{(i)}$ and $Y^{(i)}$, but is **not observed**.\n",
    "\n",
    "## Data Generation\n",
    "The student's SAT score is linear in the number of books the student read and the student's family income:\n",
    "$$Y^{(i)} = \\beta_1 X_1^{(i)} + \\beta_2 X_2^{(i)} + \\epsilon^{(i)}.$$ \n",
    "\n",
    "The number of books a student reads is linear in whether or not there was a readathon and the student's family income:\n",
    "$$X_1^{(i)} = \\gamma_1 Z^{(i)} + \\gamma_2 X_2^{(i)} + \\epsilon'^{(i)},$$\n",
    "\n",
    "### The true model was generated in the following manner:\n",
    " - Sample $Z^{(i)}\\sim N(20,5)$    $\\ \\longleftarrow\\ $   *Duration of Readathon for student* $i$ \n",
    " - Sample $X_2^{(i)} \\sim \\text{Normal}(50, 10)$   $\\ \\longleftarrow\\ $   *Income in tens of thousands for the family of student* $i$ **(unobserved variable)**\n",
    " - Generate $X_1^{(i)}$ by setting $\\gamma_1 = \\gamma_2 =1$ and sampling a noise $\\epsilon'^{(i)}\\sim N(0,5)$   $\\ \\longleftarrow\\ $  *Number of books read by student* $i$\n",
    " - Generate $Y_i^{(i)}$ by setting $\\beta_1 = 5$, $\\beta_2 = 12$  and sampling a noise $\\epsilon^{(i)}\\sim N(0,10)$ $\\ \\longleftarrow\\ $  *SAT score for student* $i$\n",
    "\n",
    "## Load the data\n",
    "Run the cells below to load and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify: Just run this to load the data\n",
    "student_data = pd.read_csv(\"SAT_data.csv\")\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pairplot illustrating the pairwise correlations between different columns in the dataset\n",
    "fig = sns.pairplot(student_data,  plot_kws=dict(marker=\"o\", alpha = 0.5))\n",
    "for i, j in zip(*np.triu_indices_from(fig.axes, 1)):\n",
    "    fig.axes[i, j].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above on the main diagonal we have the histograms of each variable, and on the off-diagonals we have scatter plots illustrating the corelations between pair of variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Understanding the Model\n",
    "\n",
    "## 1.a Correlations between variables\n",
    "### i) `TODO`: Just by inspecting the pairplot above rank in order from most correlated to least correlated the following pairwise relationships: `X_1 &  X_2`, `X_1 &  Y`, `X_1 & Z`, `X_2 & Y`, `X_2 & Z`, `Y & Z`\n",
    "### ii) `TODO`: Which of the above pairs are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) `TODO`: fill in\n",
    "\n",
    "ii) `TODO`: fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Understanding the marginal impacts\n",
    "### `TODO`: Inspect the Data Generation section above, and answer the following questions. \n",
    "#### i) What is the true causal effect of an extra book read on the SAT score (i.e. if you hold everything else constant and you read one more book by how much will the SAT score change)?\n",
    "#### ii) What is the true causal effect of increasing income by \\$10000 on the SAT score?\n",
    "#### iii) What is the true causal effect of an extra readathon day on the number of books read?\n",
    "#### iv) What is the true causal effect of increaing income by \\$10000 on the number of books read?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) `TODO`: fill in\n",
    "\n",
    "ii) `TODO`: fill in\n",
    "\n",
    "iii) `TODO`: fill in\n",
    "\n",
    "iv) `TODO`: fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares\n",
    "If we had access to income data $X_2$, then we could estimate directely $\\beta_1$, $\\beta_2$, $\\gamma_1$, $\\gamma_2$ from the data by setting up a linear regression problem and finding Ordinary Least Squares estimator. \n",
    "\n",
    "$$\\hat\\beta_1, \\hat\\beta_2 = \\arg\\min_{\\beta_1, \\beta_2}\\Vert Y - \\beta_1X_1 - \\beta_2X_2 \\Vert_2^2$$\n",
    "$$\\hat\\gamma_1, \\hat\\gamma_2 = \\arg\\min_{\\gamma_1, \\gamma_2}\\Vert X_1 - \\gamma_1Z - \\gamma_2X_2 \\Vert_2^2$$\n",
    "\n",
    "To find OLS estimators we will use [`sm.OLS`](https://www.statsmodels.org/stable/examples/notebooks/generated/ols.html?highlight=ols) from `statsmodels.api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here: Just examine the code\n",
    "def fit_OLS_model(df, target_variable, explanatory_variables, intercept = False):\n",
    "    \"\"\"\n",
    "    Fits an OLS model from data.\n",
    "    \n",
    "    Inputs:\n",
    "        df: pandas DataFrame\n",
    "        target_variable: string, name of the target variable\n",
    "        explanatory_variables: list of strings, names of the explanatory variables\n",
    "        intercept: bool, if True add intercept term\n",
    "    Outputs:\n",
    "        fitted_model: model containing OLS regression results\n",
    "    \"\"\"\n",
    "    \n",
    "    target = df[target_variable]\n",
    "    inputs = df[explanatory_variables]\n",
    "    if intercept:\n",
    "        inputs = sm.add_constant(inputs)\n",
    "    \n",
    "    fitted_model = sm.OLS(target, inputs).fit()\n",
    "    return(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the OLS estimators for gamma_1 and beta_2\n",
    "gammas_model = fit_OLS_model(student_data, 'NumBooks', ['ReadathonDuration', 'Income'])\n",
    "print(gammas_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the fitted_estimators\n",
    "gammas = gammas_model.params\n",
    "print(\"The estimated causal effect on number of books read of an additional Readathon day is {:.2f}\".format(gammas[0]))\n",
    "print(\"The estimated causal effect on number of books read of an additional $10000 is {:.2f}\".format(gammas[1]))\n",
    "# The numbers you get should be very close to you answer in 1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c Estimate causal effect of `NumBooks` and `Income` on the SAT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute OLS estimators for beta_1 and beta_2\n",
    "betas_model = # TODO: fill in\n",
    "print(betas_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the fitted_estimators\n",
    "betas = betas_model.params\n",
    "print(\"The estimated causal effect on SAT score of an additional book read is {:.2f}\".format(betas[0]))\n",
    "print(\"The estimated causal effect on SAT score of an additional $10000 is {:.2f}\".format(betas[1]))\n",
    "# The numbers you get should be very close to you answer in 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: Do not modify\n",
    "assert np.abs(betas[0]-5)< 0.1\n",
    "assert np.abs(betas[1]-12)< 0.1\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Question 1 we saw how we can estimate all causal relationships if we have access to the income variable. However in our actual data we **do not observe Income**.\n",
    "\n",
    "## Goal: estimate $\\beta_1$, the true causal effect of the number of books a student reads on their SAT score without access to the Income variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive OLS: OLS on the observed variables $X_1$, $Y$.\n",
    "The confounding variable $X_2$ (family income) is unfortunately unobserved. We will start by somewhat \"naively\" attempting to estimate the causal effect $\\beta_1$ by using plain linear regression (OLS) on the observed variables $X_1$ and $Y$. This time we will include an intercept term:\n",
    "\n",
    "$$\\hat\\beta_1, \\hat c = \\arg\\min_{\\beta_1, c} \\Vert Y - \\beta_1X_1 - c \\Vert^2_2$$\n",
    "\n",
    "## 2.a. Fit Naive OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit OLS parameters to predict Y from X_1.\n",
    "beta_naive_model = # TODO:fill in\n",
    "print(beta_naive_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: Do not modify\n",
    "params = beta_naive_model.params\n",
    "assert len(params)==2\n",
    "assert np.abs(params[0] - 42.85)<0.5\n",
    "assert np.abs(params[1] - 12.96)<0.2\n",
    "print('Test Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Naive OLS estimate of beta_1 is {:.2f}, while the true beta_1 is {}\".format(beta_naive_model.params[1], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b Does the Naive approach overestimate or under estimate the value of reading books?\n",
    "`TODO`: Answer this question by comparing the naive estimate and the true value of $\\beta_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO`: fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Instrumental variables and 2SLS\n",
    "\n",
    "To eliminate the bias, we turn to instrumental variables. In the first stage, we \"predict\" the number of books a student read from whether or not they had a readathon, $Z$, producing an estimate $\\hat{X_1}$. Then, in the second stage, we regress the SAT score $Y$ onto the predicted number of books read $\\hat{X_1}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a. Stage 1: Predict treatment variable $\\hat{X}_1$ from instrumental variable $Z$\n",
    "\n",
    "### Fit OLS parameters to predict $X_1$ from $Z$\n",
    "$$\\hat\\gamma_1, \\hat c = \\arg\\min_{\\gamma_1, c} \\Vert X_2 - \\gamma_1Z - c\\Vert_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit OLS parameters to predict X_1 from Z\n",
    "gamma1_model = # TODO: fill in\n",
    "print(gamma1_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: Do not modify\n",
    "params = gamma1_model.params\n",
    "assert len(params)==2\n",
    "assert np.abs(params[0] - 50.16)<0.5\n",
    "assert np.abs(params[1] - 1)<0.1\n",
    "print('Test Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The OLS estimate of gamma_1 is {:.3f}, while the true gamma_1 is {}\".format(gamma1_model.params[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TODO`: We observe that the estimate of $\\gamma_1$ above is very close to the true value, even though we don't make use of the `Income` variable. How can you explain this?\n",
    "**Hint**: Think about independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO`: fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can use the OLS model above to create $\\hat X_1$ predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions for number of books read\n",
    "intercept_OLS = gamma1_model.params[0]\n",
    "gamma1_OLS = gamma1_model.params[1]\n",
    "X_1_hat = intercept_OLS + gamma1_OLS*student_data['ReadathonDuration']\n",
    "\n",
    "# Add the predictions to the student_data dataframe\n",
    "student_data['PredictedNumBooks'] = X_1_hat\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Stage 2: Estimate target $Y$ from predicted treatment variable $\\hat{X}_1$\n",
    "Fit OLS parameters to predict $Y$ from the predicted $\\hat X_1$\n",
    "$$\\hat \\beta_1, \\hat c = \\arg\\min_{\\beta_1, c}\\Vert Y-\\beta_1\\hat X_1 - c\\Vert_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit OLS parameters to predict Y from the predicted X_1_hat.\n",
    "beta1_model = # TODO: fill in\n",
    "print(beta1_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: Do not modify\n",
    "params = beta1_model.params\n",
    "assert len(params)==2\n",
    "assert np.abs(params[0] - 612)<5\n",
    "assert np.abs(params[1] - 4.84)<0.3\n",
    "print('Test Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 2SLS estimate of beta_1 is {:.3f}, while the true value is {}\".format(beta1_model.params[1], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.c. Answer the following conceptual questions:\n",
    "\n",
    "### i) Which technique produced a better estimate of $\\beta_1$, naive OLS or 2SLS?\n",
    "### ii) Give a plausible scenario where the organizing a Readathon would not serve as an appropriate Intrumental Variable (IV).\n",
    "**Hint** Recall what properties should an IV satisfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) `TODO`:fill in\n",
    "\n",
    "ii) `TODO`:fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('cute_gecko.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "imgplot.axes.get_xaxis().set_visible(False)\n",
    "imgplot.axes.get_yaxis().set_visible(False)\n",
    "print(\"Yay, you've made it to the end of Lab 7!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
