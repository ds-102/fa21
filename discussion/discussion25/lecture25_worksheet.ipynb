{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "toxic-cruise",
   "metadata": {},
   "source": [
    "# Lecture worksheet 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-mission",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-relevance",
   "metadata": {},
   "source": [
    "### Q1.1 True/False\n",
    "\n",
    "(a) If we can make privacy guarantees about our data collection and/or analysis, then we have resolved any and all ethical concerns around using the data.\n",
    "\n",
    "(b) If an algorithm is $\\epsilon$-differentially private, then we can find out whether a certain individual is in the dataset with probability $\\epsilon$.\n",
    "\n",
    "(c) A linkage attack `JOIN`s a publicly available dataset with an \"anonymized\" one to re-identify individuals.\n",
    "\n",
    "### Q1.2 How identifiable are you?\n",
    "\n",
    "*Note: if you do not feel comfortable submitting any information to the sites below, you may skip parts or all of this question, but note that your privacy-paranoid instructor trusts the organizations and institutions who run the sites. -Ramesh*\n",
    "\n",
    "Please do **not** put your personally identifiable information in your submission!\n",
    "\n",
    "(a) Try the EFF's [Cover Your Tracks](https://coveryourtracks.eff.org/) site, which tells you how uniquely identifiable your browser is as you use the internet. Do the results surprise you?\n",
    "\n",
    "(b) Try Latanya Sweeney's [How Unique Am I?](https://aboutmyinfo.org/identity) tool. Before you click submit, try to guess how many other people will have the same values as you. Do the results surprise you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-antarctica",
   "metadata": {},
   "source": [
    "## Question 2: Laplace mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-angola",
   "metadata": {},
   "source": [
    "One of the most widely used mechanisms for differential privacy is the Laplace mechanism. The idea is as follows. Suppose that we want to report a statistic $f(\\cdot)$, which takes as input a database. For example, $D$ could be a database with the salaries of all residents of Berkeley, and $f(D)$ could be the average salary in $D$. Denote by $D$ and $D'$ generic neighboring databases (meaning they are only one entry different). Define the sensitivity of f as:\n",
    "\n",
    "$$\n",
    "\\Delta_f = \\max_{D, D' \\text{neighbors}} |f(D)−f(D')|\n",
    "$$\n",
    "\n",
    "The Laplace mechanism reports \n",
    "$$\n",
    "A_{Lap}(D) = f(D) + Z_\\epsilon,\n",
    "$$ \n",
    "\n",
    "where $Z_\\epsilon$ is distributed according to the zero-mean Laplace distribution with parameter $\\frac{\\Delta_f}{\\epsilon}$ , denoted $\\text{Lap}\\left(0, \\frac{\\Delta_f}{\\epsilon}\\right)$. \n",
    "\n",
    "The Laplace distribution $\\text{Lap}(\\mu, b)$ is given by the following density: \n",
    "\n",
    "$$\n",
    "  p(x)= \\frac{1}{2b}\\exp\\left\\{{−\\frac{|x−\\mu|}{b}}\\right\\}\n",
    "$$\n",
    "\n",
    "The Laplace distribution is essentially a two-sided exponential distribution: see [Wikipedia](https://en.wikipedia.org/wiki/Laplace_distribution) for more.\n",
    "\n",
    "\n",
    "### Q2.1\n",
    "\n",
    "Prove that the Laplace mechanism is $\\epsilon$-differentially private. More precisely, show\n",
    "that for all $D'$ that are neighboring to our database $D$, we have\n",
    "\n",
    "$$\n",
    "\\frac{P(A_{Lap}(D) = a)}{P(A_{Lap}(D') = a)} ≤ e^{\\epsilon}\n",
    "$$\n",
    "\n",
    "### Q2.2 \n",
    "\n",
    "Privacy alone isn't useful unless our answer is also accurate: after all, we could always just report random noise. We also would like to guarantee that $A_{Lap}(D)$ is close to $f(D)$ with high probability.\n",
    "\n",
    "(a) (Optional) If $X \\sim \\text{Lap}(0, b)$, show that $P(|X| \\geq t) \\leq 2e^{-\\frac{t}{b}}$.\n",
    "\n",
    "(b) Using the fact stated in (a), prove that:\n",
    "\n",
    "$$\n",
    "P\\left(|A_{Lap}(D) - f(D)| \\geq t\\right) \\leq 2\\exp\\left\\{-\\frac{t\\epsilon}{\\Delta_f}\\right\\}\n",
    "$$\n",
    "\n",
    "(c) For a fixed level of privacy $\\epsilon$, what can you conclude about the tradeoff between sensitivity $\\Delta_f$ and accuracy? Does the result make intuitive sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-surname",
   "metadata": {},
   "source": [
    "## Question 3: Post-processing and differential privacy\n",
    "\n",
    "An important property of differential privacy is that it is preserved under post-processing. In other words, if $A(D)$ is an $\\epsilon$-differentially private statistic, then for any function $g$, $g(A(D))$ is still differentially private.\n",
    "\n",
    "Prove this fact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
