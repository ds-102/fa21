{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parental-treat",
   "metadata": {},
   "source": [
    "# Lecture worksheet 25 solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-preserve",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-fortune",
   "metadata": {},
   "source": [
    "### Q1.1 True/False\n",
    "\n",
    "(a) If we can make privacy guarantees about our data collection and/or analysis, then we have resolved any and all ethical concerns around using the data.\n",
    "\n",
    "**SOLUTION**: False. Privacy alone is not enough of a guarantee: there are many unethical uses of data that preserve privacy protections (e.g., building discriminatory algorithms).\n",
    "\n",
    "(b) If an algorithm is $\\epsilon$-differentially private, then we can find out whether a certain individual is in the dataset with probability $\\epsilon$.\n",
    "\n",
    "**SOLUTION**: False: this is not the definition of differential privacy.\n",
    "\n",
    "(c) A linkage attack `JOIN`s a publicly available dataset with an \"anonymized\" one to re-identify individuals.\n",
    "\n",
    "**SOLUTION**: True: this is the definition of a linkage attack.\n",
    "\n",
    "### Q1.2 How identifiable are you?\n",
    "\n",
    "*Note: if you do not feel comfortable submitting any information to the sites below, you may skip parts or all of this question, but note that your privacy-paranoid instructor trusts the organizations and institutions who run the sites. -Ramesh*\n",
    "\n",
    "Please do **not** put your personally identifiable information in your submission!\n",
    "\n",
    "(a) Try the EFF's [Cover Your Tracks](https://coveryourtracks.eff.org/) site, which tells you how uniquely identifiable your browser is as you use the internet. Do the results surprise you?\n",
    "\n",
    "(b) Try Latanya Sweeney's [How Unique Am I?](https://aboutmyinfo.org/identity) tool. Before you click submit, try to guess how many other people will have the same values as you. Do the results surprise you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-universe",
   "metadata": {},
   "source": [
    "## Question 2: Laplace mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-spouse",
   "metadata": {},
   "source": [
    "One of the most widely used mechanisms for differential privacy is the Laplace mechanism. The idea is as follows. Suppose that we want to report a statistic $f(\\cdot)$, which takes as input a database. For example, $D$ could be a database with the salaries of all residents of Berkeley, and $f(D)$ could be the average salary in $D$. Denote by $D$ and $D'$ generic neighboring databases (meaning they are only one entry different). Define the sensitivity of f as:\n",
    "\n",
    "$$\n",
    "\\Delta_f = \\max_{D, D' \\text{neighbors}} |f(D)−f(D')|\n",
    "$$\n",
    "\n",
    "The Laplace mechanism reports \n",
    "$$\n",
    "A_{Lap}(D) = f(D) + Z_\\epsilon,\n",
    "$$ \n",
    "\n",
    "where $Z_\\epsilon$ is distributed according to the zero-mean Laplace distribution with parameter $\\frac{\\Delta_f}{\\epsilon}$ , denoted $\\text{Lap}\\left(0, \\frac{\\Delta_f}{\\epsilon}\\right)$. \n",
    "\n",
    "The Laplace distribution $\\text{Lap}(\\mu, b)$ is given by the following density: \n",
    "\n",
    "$$\n",
    "  p(x)= \\frac{1}{2b}\\exp\\left\\{{−\\frac{|x−\\mu|}{b}}\\right\\}\n",
    "$$\n",
    "\n",
    "The Laplace distribution is essentially a two-sided exponential distribution: see [Wikipedia](https://en.wikipedia.org/wiki/Laplace_distribution) for more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-premium",
   "metadata": {},
   "source": [
    "### Q2.1\n",
    "\n",
    "Prove that the Laplace mechanism is $\\epsilon$-differentially private. More precisely, show\n",
    "that for all $D'$ that are neighboring to our database $D$, we have\n",
    "\n",
    "$$\n",
    "\\frac{P(A_{Lap}(D) = a)}{P(A_{Lap}(D') = a)} ≤ e^{\\epsilon}\n",
    "$$\n",
    "\n",
    "**SOLUTION**:\n",
    "\n",
    "*Note: because $A_{Lap}$ is continuous, the probabilities above are technically zero. Instead, we'll consider the ratio of probabilities that $A_{Lap}$ is between $a$ and some infinitesimally close value $a + \\alpha$, so that we can use the ratio of densities.*\n",
    "\n",
    "We know that $A_{Lap}$ produces a noisy version of $f$:\n",
    "\n",
    "$$\n",
    "A_{Lap}(D) = f(D) + Z_\\epsilon \\\\\n",
    "A_{Lap}(D') = f(D') + Z_\\epsilon \\\\\n",
    "$$\n",
    "\n",
    "Since $f(D)$ is a constant, $A$ produces a shifted Laplace distribution:\n",
    "\n",
    "$$\n",
    "A_{Lap}(D) \\sim \\text{Laplace}\\left(f(D), \\frac{\\Delta_f}{\\epsilon}\\right) \\\\\n",
    "A_{Lap}(D') \\sim \\text{Laplace}\\left(f(D'), \\frac{\\Delta_f}{\\epsilon}\\right)\n",
    "$$\n",
    "\n",
    "Now, we have all the information we need to begin:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{P(A_{Lap}(D) = a)}{P(A_{Lap}(D') = a)} \n",
    "    &= \\frac{%\n",
    "        \\frac{1}{2b}\\exp\\left\\{{−\\frac{|a−f(D)|}{\\Delta_f\\,/\\,\\epsilon}}\\right\\}}{%\n",
    "        \\frac{1}{2b}\\exp\\left\\{{−\\frac{|a−f(D')|}{\\Delta_f\\,/\\,\\epsilon}}\\right\\}} \\\\\n",
    "    &= \\exp\\left\\{\\frac{\\epsilon}{\\Delta_f}\\left[\\left|a−f(D')\\right| - \\left|a-f(D)\\right|\\right]\\right\\}\n",
    "\\end{align}\n",
    "\n",
    "Now, we have to relate the quantity $\\left|a−f(D')\\right| - \\left|a-f(D)\\right|$, as it appears above, to the quantities we know about. In particular, we know from the definition of $\\Delta_f$ that $|f(D)−f(D')| \\leq \\Delta_f$. So, we'll use a version of the [triangle inequality](https://en.wikipedia.org/wiki/Triangle_inequality#Metric_space), which states that \n",
    "\n",
    "$$\n",
    "|A - B| - |A-C| \\leq |B-C|\n",
    "$$\n",
    "\n",
    "Try proving it yourself by drawing out $A$, $B$, and $C$ on a number line.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{P(A_{Lap}(D) = a)}{P(A_{Lap}(D') = a)} \n",
    "    &\\leq \\exp\\left\\{\\frac{\\epsilon}{\\Delta_f}|f(D) - f(D')|\\right\\}\\\\\n",
    "    &\\leq \\exp\\left\\{\\frac{\\epsilon}{\\Delta_f}\\Delta_f\\right\\} \\\\\n",
    "    &= e^{\\epsilon}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-freedom",
   "metadata": {},
   "source": [
    "\n",
    "### Q2.2 \n",
    "\n",
    "Privacy alone isn't useful unless our answer is also accurate: after all, we could always just report random noise. We also would like to guarantee that $A_{Lap}(D)$ is close to $f(D)$ with high probability.\n",
    "\n",
    "(a) (Optional) If $X \\sim \\text{Lap}(0, b)$, show that $P(|X| \\geq t) \\leq e^{-\\frac{t}{b}}$.\n",
    "\n",
    "**SOLUTION**: By symmetry, we can compute $P(X \\geq t)$ (for $t > 0$) and double the result.\n",
    "\n",
    "\\begin{align}\n",
    "P(X \\geq t) &= \\int_t^\\infty \\frac{1}{2b} \\exp\\left\\{-\\frac{|x|}{b}\\right\\}\\,dx\n",
    "\\end{align}\n",
    "\n",
    "Over the domain of the integral, $x$ is always positive, so $|x| = x$. Evaluating the integral, we find:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(X \\geq t) \n",
    "    &= \\left[-\\frac{1}{2} \\exp\\left\\{-\\frac{x}{b}\\right\\}\\right]_t^\\infty \\\\\n",
    "    &= \\frac{1}{2}e^{-t/b}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "By symmetry, $P(X \\leq -t) = P(X \\geq t)$, and $P(|X| \\geq t) = P(X \\leq -t) + P(X \\geq t)$. So, $P(|X| \\geq t) = e^{-\\frac{t}{b}}$.\n",
    "\n",
    "(b) Using the fact stated in (a), prove that:\n",
    "\n",
    "$$\n",
    "P\\left(|A_{Lap}(D) - f(D)| \\geq t\\right) \\leq 2\\exp\\left\\{-\\frac{t\\epsilon}{\\Delta_f}\\right\\}\n",
    "$$\n",
    "\n",
    "**SOLUTION**: We know that $A_{Lap}(D) = f(D) + Z_\\epsilon$. So, $A_{Lap}(D) - f(D) = Z_\\epsilon$. And from above, we know that $Z \\sim \\text{Lap}\\left(0, \\frac{\\Delta_f}{\\epsilon}\\right)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P\\left(|A_{Lap}(D) - f(D)| \\geq t\\right)\n",
    "    &= P\\left(|Z_\\epsilon| \\geq t\\right) \\\\\n",
    "    &= \\exp\\left\\{-\\frac{t\\epsilon}{\\Delta_f}\\right\\}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "(c) For a fixed level of privacy $\\epsilon$, what can you conclude about the tradeoff between sensitivity $\\Delta_f$ and accuracy? Does the result make intuitive sense?\n",
    "\n",
    "**SOLUTION**: The quantity from part (b) (i.e., the RHS of the concentration inequality) gives us a measure of accuracy: the smaller the number, the more accurate $A_{Lap}$ is. We can see that as $\\Delta_f$ increases from $0$ to $\\infty$, the quantity being exponentiated goes from $-\\infty$ to $0$: in other words, our bound goes from 0 to 1. To interpret this, small values of $\\Delta_f$ give us good accuracy, while large values of $\\Delta_f$ result in poor accuracy.\n",
    "\n",
    "This makes intuitive sense: if we have a function $f$ that isn't very sensitive to removing a row from the data, then we don't need to add very much noise. But if our function is very sensitive, then we need more noise to ensure differential privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-resolution",
   "metadata": {},
   "source": [
    "## Question 3: Post-processing and differential privacy\n",
    "\n",
    "An important property of differential privacy is that it is preserved under post-processing. In other words, if $A(D)$ is an $\\epsilon$-differentially private statistic, then for any function $g$, $g(A(D))$ is still differentially private.\n",
    "\n",
    "Prove this fact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
