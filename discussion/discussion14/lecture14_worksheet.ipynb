{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture worksheet 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (racial discrimination): \n",
    "\n",
    "In this problem, we analyze the resumes dataset from [Bertrand, M. and Mullainathan, S. (2004)](https://www.nber.org/system/files/working_papers/w9873/w9873.pdf).\n",
    "\n",
    "We have defined functions to implement the estimators that we talked about in lecture. Read through the code and make sure you understand what the functions are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for lecture worksheet\n",
    "\n",
    "def get_Neyman_ATE(data_df, outcome_var, treatment_var, treatment_label=1):\n",
    "    \n",
    "    treated_indicator = (data_df[treatment_var] == treatment_label)\n",
    "    Y_t = data_df[treated_indicator][outcome_var]\n",
    "    Y_c = data_df[~treated_indicator][outcome_var]\n",
    "    tau_hat = Y_t.mean() - Y_c.mean()\n",
    "    \n",
    "    return tau_hat\n",
    "\n",
    "def get_Neyman_var(data_df, outcome_var, treatment_var, treatment_label=1):\n",
    "    \n",
    "    treated_indicator = (data_df[treatment_var] == treatment_label)\n",
    "    Y_t = data_df[treated_indicator][outcome_var]\n",
    "    Y_c = data_df[~treated_indicator][outcome_var]\n",
    "    s1_sq = np.std(Y_t, ddof=1)\n",
    "    s0_sq = np.std(Y_c, ddof=1)\n",
    "    n_1 = len(Y_t)\n",
    "    n_0 = len(Y_c)\n",
    "    V_Neyman_hat = s1_sq/n_1 + s0_sq/n_0\n",
    "    \n",
    "    return V_Neyman_hat\n",
    "\n",
    "def get_symmetric_CI(estimate, sd, coverage=0.95):\n",
    "    \n",
    "    alpha = (1-coverage)/2\n",
    "    z_alpha = stats.norm.ppf(1-alpha)\n",
    "    CI = (estimate - z_alpha*sd, estimate + z_alpha*sd)\n",
    "    \n",
    "    return CI\n",
    "\n",
    "def get_Neyman_null_p_val(estimate, sd):\n",
    "    \n",
    "    p_val = 1 - stats.norm.cdf(estimate / sd)\n",
    "    \n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2a) What is the difference-in-means estimate of the ATE? How would you interpret this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b) Compute a 95\\% confidence interval for the ATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2c) Compute the Neyman null p-value and compare it to the null p-value from the Fisher exact test. Which is smaller? Why do you think this is the case? Does this mean that one test is better than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d) (**optional**) Compute the two p-values again, but for the subgroup of men."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (compliance): \n",
    "\n",
    "In lecture, we talked about the problem of compliance, where individuals do not comply with their assigned treatment, and cross over to the other treatment group (e.g. individuals randomized into Medicaid don't enroll in Medicaid and vice versa). Whenever this happens, researchers usually have two choices:\n",
    "1. Analyze the individuals as randomized (intention-to-treat analysis), or \n",
    "2. Analyze the individuals according to the treatment group (per protocol analysis).\n",
    "\n",
    "Discuss what are the pros and cons of both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (hypothetical randomized experiments): \n",
    "\n",
    "Think of a hypothesis you would like to test, and construct a hypothetical randomized experiment to test it. Are there hypotheses that are fundamentally untestable?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
