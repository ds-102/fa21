{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture worksheet 14 solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (racial discrimination): \n",
    "\n",
    "In this problem, we analyze the resumes dataset from [Bertrand, M. and Mullainathan, S. (2004)](https://www.nber.org/system/files/working_papers/w9873/w9873.pdf).\n",
    "\n",
    "We have defined functions to implement the estimators that we talked about in lecture. Read through the code and make sure you understand what the functions are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for lecture worksheet\n",
    "\n",
    "def get_Neyman_ATE(data_df, outcome_var, treatment_var, treatment_label=1):\n",
    "    \n",
    "    treated_indicator = (data_df[treatment_var] == treatment_label)\n",
    "    Y_t = data_df[treated_indicator][outcome_var]\n",
    "    Y_c = data_df[~treated_indicator][outcome_var]\n",
    "    tau_hat = Y_t.mean() - Y_c.mean()\n",
    "    \n",
    "    return tau_hat\n",
    "\n",
    "def get_Neyman_var(data_df, outcome_var, treatment_var, treatment_label=1):\n",
    "    \n",
    "    treated_indicator = (data_df[treatment_var] == treatment_label)\n",
    "    Y_t = data_df[treated_indicator][outcome_var]\n",
    "    Y_c = data_df[~treated_indicator][outcome_var]\n",
    "    s1_sq = np.var(Y_t, ddof=1) # Originally a typo here, we had written np.std instead of np.var\n",
    "    s0_sq = np.var(Y_c, ddof=1)\n",
    "    n_1 = len(Y_t)\n",
    "    n_0 = len(Y_c)\n",
    "    V_Neyman_hat = s1_sq/n_1 + s0_sq/n_0\n",
    "    \n",
    "    return V_Neyman_hat\n",
    "\n",
    "def get_symmetric_CI(estimate, sd, coverage=0.95):\n",
    "    \n",
    "    alpha = (1-coverage)/2\n",
    "    z_alpha = stats.norm.ppf(1-alpha)\n",
    "    CI = (estimate - z_alpha*sd, estimate + z_alpha*sd)\n",
    "    \n",
    "    return CI\n",
    "\n",
    "def get_Neyman_null_p_val(estimate, sd):\n",
    "    \n",
    "    p_val = 1 - stats.norm.cdf(estimate / sd)\n",
    "    \n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes_df = pd.read_csv(\"resume.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a) What is the difference-in-means estimate of the ATE? How would you interpret this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATE = get_Neyman_ATE(resumes_df, \"call\", \"race\", \"white\")\n",
    "np.round(ATE, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**: Resumes with stereotypically black names had 3.2% fewer callbacks then resumes with stereotypically white names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b) Compute a 95\\% confidence interval for the ATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01677459474666388, 0.04729111367222729)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = np.sqrt(get_Neyman_var(resumes_df, \"call\", \"race\", \"white\"))\n",
    "get_symmetric_CI(ATE, sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1c) Compute the Neyman null p-value and compare it to the null p-value from the Fisher exact test. Which is smaller? Why do you think this is the case? Does this mean that one test is better than the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9383722123067493e-05"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val = get_Neyman_null_p_val(ATE, sd)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.379373553950655e-05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab = pd.crosstab(resumes_df[\"call\"], resumes_df[\"race\"])\n",
    "_, p_val = stats.fisher_exact(tab, alternative=\"greater\")\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**: Here, as opposed to lecture, we do one-sided Fisher's exact test (so the alternative is that some units had positive treatment effect). Both $p$-values are quite similar, but the exact test $p$-value is slightly bigger. Contrary to my (Yan Shuo's) original belief, this is [pretty representative](https://projecteuclid.org/journals/statistical-science/volume-32/issue-3/A-Paradox-from-Randomization-Based-Causal-Inference/10.1214/16-STS571.full) of what usually happens, and the underlying reasons more complex than I thought (hence way beyond the scope of the course).\n",
    "\n",
    "Despite the Fisher null being more stringent than the Neyman null, the Neyman test is only asymptotically valid, and can be shown to be anti-conservative in smaller samples.\n",
    "\n",
    "Both tests have their uses. Fisher's exact test is finite sample valid, and is especially useful for small sample sizes, but they whereas the Neyman null is often more interesting.\n",
    "\n",
    "*Note: There was originally a typo in the code which made the Neyman $p$-value much larger.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d) (**optional**) Compute the two p-values again, but for the subgroup of men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_resumes_df = resumes_df[resumes_df[\"sex\"] == \"male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATE = get_Neyman_ATE(men_resumes_df, \"call\", \"race\", \"white\")\n",
    "np.round(ATE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.779562305029292e-05, 0.060833507985448315)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = np.sqrt(get_Neyman_var(men_resumes_df, \"call\", \"race\", \"white\"))\n",
    "get_symmetric_CI(ATE, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02506707445738776"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val = get_Neyman_null_p_val(ATE, sd)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032876140169162425"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab = pd.crosstab(men_resumes_df[\"call\"], men_resumes_df[\"race\"])\n",
    "_, p_val = stats.fisher_exact(tab, alternative=\"greater\")\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (compliance): \n",
    "\n",
    "In lecture, we talked about the problem of compliance, where individuals do not comply with their assigned treatment, and cross over to the other treatment group (e.g. individuals randomized into Medicaid don't enroll in Medicaid and vice versa). Whenever this happens, researchers usually have two choices:\n",
    "1. Analyze the individuals as randomized (intention-to-treat analysis), or \n",
    "2. Analyze the individuals according to the treatment group (per protocol analysis).\n",
    "\n",
    "Discuss what are the pros and cons of both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**: Under per protocol analysis, treatment is no longer randomized, so we might have confounding. Under the intention to-treat analysis, we are not measuring the treatment effect, but the effect of the randomization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (hypothetical randomized experiments): \n",
    "\n",
    "Think of a hypothesis you would like to test, and construct a hypothetical randomized experiment to test it. Are there hypotheses that are fundamentally untestable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**: I'm interested in the effect of working from home on mental health. Hypothetically, we could randomize individuals into working from home vs not.\n",
    "\n",
    "Some interventions may not be well-defined. For instance, it may not be meaningful to test the effect of obesity on mortality, because obesity is so fundamentally tied to other health aspects that it cannot be isolated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
